{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0a8n9es5-R53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "F1SUbvTA7vz3"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, Activation, Dropout, RepeatVector, Embedding , TimeDistributed\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.losses import sparse_categorical_crossentropy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoQTnHPj-eAU",
        "outputId": "ee322165-7597-463f-d273-3199ce7628ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ehsanh123/NLP-Week6.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "algpdXjfnynl",
        "outputId": "128dfbe6-b0eb-45d6-9f77-ef5ef8063cb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP-Week6'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), 5.17 MiB | 19.32 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path ='/content/drive/MyDrive/NLP/spa.txt'\n",
        "path = '/content/NLP-Week6/spa.txt'\n",
        "traslation_file = open(path ,\"r\",encoding=\"utf-8\")\n",
        "raw_data = traslation_file.read()\n",
        "traslation_file.close()"
      ],
      "metadata": {
        "id": "VgvuZJ8O-5mH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Sequence\n",
        "raw_data = raw_data.split('\\n')\n",
        "pairs = [Sequence.split('\\t') for Sequence in raw_data]\n",
        "pairs = pairs[1000:20000]"
      ],
      "metadata": {
        "id": "e3fnKwLgBvQ6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRteyH9aoQev",
        "outputId": "3acbea18-db0e-4471-a8fb-ab71d871da2c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tom cares.',\n",
              " 'Tom se preocupa.',\n",
              " 'CC-BY 2.0 (France) Attribution: tatoeba.org #2203611 (CK) & #4557602 (swyter)']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sentence(sentece):\n",
        "  lower_case = sentece.lower()\n",
        "  string_punctuation = string.punctuation + \"¿\"\n",
        "  clean_sentence = lower_case.translate(str.maketrans(\"\",\"\",string_punctuation))\n",
        "  return clean_sentence"
      ],
      "metadata": {
        "id": "YCeHMiSfCAVi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(sentece):\n",
        "  text_tokenizer = Tokenizer()\n",
        "  text_tokenizer.fit_on_texts(sentece)\n",
        "  return text_tokenizer.texts_to_sequences(sentece), text_tokenizer"
      ],
      "metadata": {
        "id": "T02viQcPCM-j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean sentences\n",
        "english_sentences = [clean_sentence(pair[1]) for pair in pairs]\n",
        "spanish_sentences = [clean_sentence(pair[0]) for pair in pairs]\n",
        "# Tokenize words\n",
        "spa_text_tokenized, spa_text_tokenizer = tokenizer(spanish_sentences)\n",
        "eng_text_tokenized, eng_text_tokenizer = tokenizer(english_sentences)\n",
        "print('Maximum length spanish sentence: {}'.format (len(max(spa_text_tokenized,key=len))))\n",
        "print('Maximum length english sentence: {}'.format (len (max(eng_text_tokenized, key=len))))\n",
        "# Check language length\n",
        "spanish_vocab = len(spa_text_tokenizer. word_index) + 1\n",
        "english_vocab = len(eng_text_tokenizer.word_index) + 1\n",
        "print(\"Spanish vocabulary is of () unique words\".format (spanish_vocab))\n",
        "print (\"English vocabulary is of f) unique words\".format (english_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs7rl7GRCv6-",
        "outputId": "b031c963-9e23-4184-f924-9cd3f578f8f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum length spanish sentence: 5\n",
            "Maximum length english sentence: 9\n",
            "Spanish vocabulary is of () unique words\n",
            "English vocabulary is of f) unique words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_spanish_len = int(len(max(spa_text_tokenized, key=len)))\n",
        "\n",
        "max_english_len = int(len(max(eng_text_tokenized, key=len)))\n",
        "\n",
        "spa_pad_sentence = pad_sequences (spa_text_tokenized, max_spanish_len, padding = \"post\")\n",
        "\n",
        "eng_pad_sentence = pad_sequences (eng_text_tokenized, max_english_len, padding = \"post\")\n",
        "\n",
        "#Reshape data\n",
        "\n",
        "spa_pad_sentence = spa_pad_sentence.reshape(*spa_pad_sentence.shape, 1)\n",
        "\n",
        "eng_pad_sentence = eng_pad_sentence.reshape(*eng_pad_sentence.shape, 1)"
      ],
      "metadata": {
        "id": "8xfCR9i9lGqK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = Input(shape=(max_spanish_len,))\n",
        "\n",
        "embedding = Embedding(input_dim=spanish_vocab, output_dim=128,)(input_sequence)\n",
        "\n",
        "encoder = LSTM (64, return_sequences=False) (embedding)\n",
        "\n",
        "r_vec = RepeatVector(max_english_len) (encoder)\n",
        "\n",
        "decoder = LSTM (64, return_sequences=True, dropout=0.2) (r_vec)\n",
        "\n",
        "logits = TimeDistributed (Dense(english_vocab)) (decoder)"
      ],
      "metadata": {
        "id": "AMFVPvKIlbDH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_dec_model = Model(input_sequence, Activation('softmax') (logits))\n",
        "\n",
        "# enc_dec_model.compile(loss=sparse_categorical_crossentropy,\n",
        "# optimizer=Adam(1e-3), metrics=['accuracy'])\n",
        "\n",
        "enc_dec_model.compile(loss=sparse_categorical_crossentropy,\n",
        "optimizer=Adam(1e-3), metrics=['accuracy'])\n",
        "\n",
        "enc_dec_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "HQPOfpHTln2h",
        "outputId": "e2f1c955-e9ad-4654-8700-c65dbb194b09"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │         \u001b[38;5;34m475,904\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m7423\u001b[0m)             │         \u001b[38;5;34m482,495\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m7423\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">475,904</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7423</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">482,495</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7423</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,040,831\u001b[0m (3.97 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,040,831</span> (3.97 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,040,831\u001b[0m (3.97 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,040,831</span> (3.97 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_results = enc_dec_model.fit(spa_pad_sentence, eng_pad_sentence, batch_size=30, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzJt3BpGmaB0",
        "outputId": "044b40d2-c09f-4335-831e-b538e74110d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.6410 - loss: 4.1233\n",
            "Epoch 2/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6644 - loss: 2.4448\n",
            "Epoch 3/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.6672 - loss: 2.3327\n",
            "Epoch 4/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.6762 - loss: 2.2335\n",
            "Epoch 5/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6864 - loss: 2.1099\n",
            "Epoch 6/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6970 - loss: 1.9974\n",
            "Epoch 7/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7041 - loss: 1.9103\n",
            "Epoch 8/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7104 - loss: 1.8362\n",
            "Epoch 9/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7176 - loss: 1.7587\n",
            "Epoch 10/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7231 - loss: 1.6937\n",
            "Epoch 11/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7292 - loss: 1.6305\n",
            "Epoch 12/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7327 - loss: 1.5754\n",
            "Epoch 13/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.7384 - loss: 1.5132\n",
            "Epoch 14/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7430 - loss: 1.4623\n",
            "Epoch 15/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7470 - loss: 1.4171\n",
            "Epoch 16/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7504 - loss: 1.3678\n",
            "Epoch 17/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7551 - loss: 1.3179\n",
            "Epoch 18/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7571 - loss: 1.2831\n",
            "Epoch 19/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.7608 - loss: 1.2431\n",
            "Epoch 20/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.7650 - loss: 1.2088\n",
            "Epoch 21/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.7690 - loss: 1.1707\n",
            "Epoch 22/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7709 - loss: 1.1414\n",
            "Epoch 23/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7731 - loss: 1.1131\n",
            "Epoch 24/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7753 - loss: 1.0857\n",
            "Epoch 25/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.7778 - loss: 1.0643\n",
            "Epoch 26/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7822 - loss: 1.0261\n",
            "Epoch 27/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.7846 - loss: 1.0019\n",
            "Epoch 28/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7887 - loss: 0.9738\n",
            "Epoch 29/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7878 - loss: 0.9702\n",
            "Epoch 30/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.7954 - loss: 0.9238\n",
            "Epoch 31/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.7972 - loss: 0.9081\n",
            "Epoch 32/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.7998 - loss: 0.8901\n",
            "Epoch 33/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8016 - loss: 0.8783\n",
            "Epoch 34/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8043 - loss: 0.8580\n",
            "Epoch 35/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8072 - loss: 0.8465\n",
            "Epoch 36/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8114 - loss: 0.8211\n",
            "Epoch 37/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8150 - loss: 0.7962\n",
            "Epoch 38/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8162 - loss: 0.7886\n",
            "Epoch 39/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8179 - loss: 0.7767\n",
            "Epoch 40/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8227 - loss: 0.7524\n",
            "Epoch 41/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8239 - loss: 0.7424\n",
            "Epoch 42/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8250 - loss: 0.7373\n",
            "Epoch 43/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8278 - loss: 0.7264\n",
            "Epoch 44/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8295 - loss: 0.7082\n",
            "Epoch 45/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8317 - loss: 0.6956\n",
            "Epoch 46/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8350 - loss: 0.6840\n",
            "Epoch 47/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8365 - loss: 0.6801\n",
            "Epoch 48/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8371 - loss: 0.6680\n",
            "Epoch 49/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8416 - loss: 0.6464\n",
            "Epoch 50/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8411 - loss: 0.6437\n",
            "Epoch 51/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8425 - loss: 0.6376\n",
            "Epoch 52/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8447 - loss: 0.6324\n",
            "Epoch 53/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8476 - loss: 0.6137\n",
            "Epoch 54/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8476 - loss: 0.6102\n",
            "Epoch 55/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8507 - loss: 0.5983\n",
            "Epoch 56/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8484 - loss: 0.5959\n",
            "Epoch 57/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8506 - loss: 0.5910\n",
            "Epoch 58/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8525 - loss: 0.5779\n",
            "Epoch 59/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8541 - loss: 0.5713\n",
            "Epoch 60/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8549 - loss: 0.5628\n",
            "Epoch 61/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8564 - loss: 0.5578\n",
            "Epoch 62/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8586 - loss: 0.5466\n",
            "Epoch 63/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8586 - loss: 0.5438\n",
            "Epoch 64/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8574 - loss: 0.5461\n",
            "Epoch 65/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8597 - loss: 0.5351\n",
            "Epoch 66/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8617 - loss: 0.5313\n",
            "Epoch 67/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8645 - loss: 0.5177\n",
            "Epoch 68/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8614 - loss: 0.5247\n",
            "Epoch 69/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8621 - loss: 0.5179\n",
            "Epoch 70/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8654 - loss: 0.5066\n",
            "Epoch 71/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8659 - loss: 0.5069\n",
            "Epoch 72/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8689 - loss: 0.4889\n",
            "Epoch 73/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8671 - loss: 0.4995\n",
            "Epoch 74/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8696 - loss: 0.4879\n",
            "Epoch 75/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8681 - loss: 0.4869\n",
            "Epoch 76/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8711 - loss: 0.4768\n",
            "Epoch 77/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8702 - loss: 0.4724\n",
            "Epoch 78/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8701 - loss: 0.4759\n",
            "Epoch 79/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8737 - loss: 0.4624\n",
            "Epoch 80/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8753 - loss: 0.4596\n",
            "Epoch 81/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8742 - loss: 0.4584\n",
            "Epoch 82/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8733 - loss: 0.4587\n",
            "Epoch 83/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8753 - loss: 0.4529\n",
            "Epoch 84/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8757 - loss: 0.4498\n",
            "Epoch 85/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8770 - loss: 0.4412\n",
            "Epoch 86/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8790 - loss: 0.4393\n",
            "Epoch 87/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.8788 - loss: 0.4389\n",
            "Epoch 88/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8790 - loss: 0.4312\n",
            "Epoch 89/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8769 - loss: 0.4379\n",
            "Epoch 90/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8782 - loss: 0.4328\n",
            "Epoch 91/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8784 - loss: 0.4266\n",
            "Epoch 92/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8792 - loss: 0.4286\n",
            "Epoch 93/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8800 - loss: 0.4264\n",
            "Epoch 94/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8816 - loss: 0.4195\n",
            "Epoch 95/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8815 - loss: 0.4146\n",
            "Epoch 96/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8810 - loss: 0.4123\n",
            "Epoch 97/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8827 - loss: 0.4086\n",
            "Epoch 98/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8836 - loss: 0.4066\n",
            "Epoch 99/100\n",
            "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8819 - loss: 0.4139\n",
            "Epoch 100/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example test Sentences\n",
        "test_sentences = [\n",
        "\"How are you\",\n",
        "\"Today is Friday\",\n",
        "\"This is NLP\"\n",
        "]\n",
        "\n",
        "# Clean and Tokenize Test Sentences\n",
        "clean_test_sentences = [clean_sentence (sentence) for sentence in test_sentences]\n",
        "\n",
        "#Tokenize Test Sentences\n",
        "\n",
        "test_sequences_spa = spa_text_tokenizer.texts_to_sequences(clean_test_sentences)\n",
        "\n",
        "test_pad_sequences_spa = pad_sequences(test_sequences_spa, max_spanish_len, padding-\"post\")\n",
        "\n",
        "# Reshape Test Data\n",
        "test_pad_sequences_spa = test_pad_sequences_spa.reshape(*test_pad_sequences_spa.shape, 1)\n",
        "\n",
        "print(test_pad_sequences_spa)\n",
        "\n",
        "#Predict Translations\n",
        "\n",
        "predicted_sequences = enc_dec_model.predict(test_pad_sequences_spa)\n",
        "\n",
        "#Convert Indices to Words\n",
        "\n",
        "def sequences_to_text(sequences, tokenizer):\n",
        "\n",
        "  word_index = tokenizer.word_index\n",
        "\n",
        "  reverse_word_index = dict([(index, word) for (word, index) in word_index.items()])\n",
        "\n",
        "  return ' '.join([reverse_word_index.get(i,'?') for i in sequences])\n",
        "\n",
        "# Display Results\n",
        "\n",
        "for i, sentence in enumerate(test_sentences):\n",
        "  print(\"Input Sentence: (sentence)\")\n",
        "  print(f\"Predicted Translation: (sequences_to_text(np.argmax(predicted_sequences[i], axis-1), eng_text_tokenizer))\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "mZAvF_CXojoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4mTO-nn-rr2U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}